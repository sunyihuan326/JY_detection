{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "%matplotlib inline\n",
    "\n",
    "LABELS = [\"beefsteak\", \"cartooncookies\", \"chickenwings\", \"chiffoncake6\", \"chiffoncake8\",\n",
    "               \"cookies\", \"cranberrycookies\", \"cupcake\", \"eggtart\", \"eggtartbig\",\n",
    "               \"nofood\", \"peanuts\", \"pizzafour\", \"pizzaone\", \"pizzasix\",\n",
    "               \"pizzatwo\", \"porkchops\", \"potatocut\", \"potatol\", \"potatom\",\n",
    "               \"potatos\", \"sweetpotatocut\", \"sweetpotatol\", \"sweetpotatom\", \"sweetpotatos\",\n",
    "               \"roastedchicken\", \"toast\", \"sweetpotato_others\", \"pizza_others\",\n",
    "               \"potato_others\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dowload VOC-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_image_folder = \"E:/DataSets/KX_FOODSets_model_data/X_KX_data_27_1127/JPGImages/\"\n",
    "train_annot_folder = \"E:/DataSets/KX_FOODSets_model_data/X_KX_data_27_1127/Annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bfdd62aa15c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m## Parse annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mtrain_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseen_train_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_annotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_annot_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_image_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"N train = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-bfdd62aa15c4>\u001b[0m in \u001b[0;36mparse_annotation\u001b[1;34m(ann_dir, img_dir, labels)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;31m## make sure that the image exists:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                     \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"file does not exist!\\n{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'width'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: file does not exist!\nE:/DataSets/KX_FOODSets_model_data/X_KX_data_27_1127/JPGImages/20190910103227.jpg"
     ],
     "ename": "AssertionError",
     "evalue": "file does not exist!\nE:/DataSets/KX_FOODSets_model_data/X_KX_data_27_1127/JPGImages/20190910103227.jpg",
     "output_type": "error"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_annotation(ann_dir, img_dir, labels=[]):\n",
    "    '''\n",
    "    output:\n",
    "    - Each element of the train_image is a dictionary containing the annoation infomation of an image.\n",
    "    - seen_train_labels is the dictionary containing\n",
    "            (key, value) = (the object class, the number of objects found in the images)\n",
    "    '''\n",
    "    all_imgs = []\n",
    "    seen_labels = {}\n",
    "    \n",
    "    for ann in sorted(os.listdir(ann_dir)):\n",
    "        if \"xml\" not in ann:\n",
    "            continue\n",
    "        img = {'object':[]}\n",
    "\n",
    "        tree = ET.parse(ann_dir + ann)\n",
    "        \n",
    "        for elem in tree.iter():\n",
    "            if 'filename' in elem.tag:\n",
    "                path_to_image = img_dir + elem.text\n",
    "                img['filename'] = path_to_image\n",
    "                ## make sure that the image exists:\n",
    "                if not os.path.exists(path_to_image):\n",
    "                    assert False, \"file does not exist!\\n{}\".format(path_to_image)\n",
    "            if 'width' in elem.tag:\n",
    "                img['width'] = int(elem.text)\n",
    "            if 'height' in elem.tag:\n",
    "                img['height'] = int(elem.text)\n",
    "            if 'object' in elem.tag or 'part' in elem.tag:\n",
    "                obj = {}\n",
    "                \n",
    "                for attr in list(elem):\n",
    "                    if 'name' in attr.tag:\n",
    "                        \n",
    "                        obj['name'] = attr.text\n",
    "                        \n",
    "                        if len(labels) > 0 and obj['name'] not in labels:\n",
    "                            break\n",
    "                        else:\n",
    "                            img['object'] += [obj]\n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if obj['name'] in seen_labels:\n",
    "                            seen_labels[obj['name']] += 1\n",
    "                        else:\n",
    "                            seen_labels[obj['name']]  = 1\n",
    "                        \n",
    "\n",
    "                            \n",
    "                    if 'bndbox' in attr.tag:\n",
    "                        for dim in list(attr):\n",
    "                            if 'xmin' in dim.tag:\n",
    "                                obj['xmin'] = int(round(float(dim.text)))\n",
    "                            if 'ymin' in dim.tag:\n",
    "                                obj['ymin'] = int(round(float(dim.text)))\n",
    "                            if 'xmax' in dim.tag:\n",
    "                                obj['xmax'] = int(round(float(dim.text)))\n",
    "                            if 'ymax' in dim.tag:\n",
    "                                obj['ymax'] = int(round(float(dim.text)))\n",
    "\n",
    "        if len(img['object']) > 0:\n",
    "            all_imgs += [img]\n",
    "                        \n",
    "    return all_imgs, seen_labels\n",
    "\n",
    "## Parse annotations \n",
    "train_image, seen_train_labels = parse_annotation(train_annot_folder,train_image_folder, labels=LABELS)\n",
    "print(\"N train = {}\".format(len(train_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output : train_image\n",
    "- train_image是一个字典，它包含了图片以及标注信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_image[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize output : seen_train_labels\n",
    "\n",
    "- VOC数据集一共有20个类别，下面将这些类别的数量分布情况可视化出来:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_pos = np.arange(len(seen_train_labels))\n",
    "fig = plt.figure(figsize=(13,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.barh(y_pos,list(seen_train_labels.values()))\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(list(seen_train_labels.keys()))\n",
    "ax.set_title(\"The total number of objects = {} in {} images\".format(\n",
    "    np.sum(list(seen_train_labels.values())),len(train_image)\n",
    "))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering\n",
    "\n",
    "在论文[YOLO9000:Better, Faster, Stronger](https://arxiv.org/pdf/1612.08242.pdf) 强烈建议我们使用聚类分析得到先验anchor的尺寸大小，原文这样说到:\n",
    "\n",
    "<blockquote>\n",
    "Dimension Clusters:\n",
    "we encounter two issues with anchor boxes when using them with YOLO.\n",
    "The first is that the box dimensions are hand picked. \n",
    "the network can learn to adjust the boxes appropriately but if we pick better priors for the network to start with, we can make it easier for the network to learn to predict good detections.\n",
    "</blockquote>\n",
    "<blockquote>\n",
    "Instead of choosing priors by hand, we run k-means clustering on the training set bounding boxes to automatically find good priors. If we use standard k-means with Euclidean distance learger boxes generate more error than smaller boxes. However, what we really want are priors that lead to good IOU scores, which is indepedndent of the size of the box. Thus for our distance metric we use 1 - IOU(box,centroid)\n",
    "</blockquote>\n",
    "因此，让我们首先为K-means聚类准备要输入数据。 输入数据指的是ground truth bounding box的宽度和高度来作为特征。 考虑到在不同尺度下的场景中，每个boundingbox的尺寸不一。因此，非常有必要来标准化边界框的宽度和高度与图像的宽度和高度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "wh = []\n",
    "for anno in train_image:\n",
    "    aw = float(anno['width'])  # width of the original image\n",
    "    ah = float(anno['height']) # height of the original image\n",
    "    for obj in anno[\"object\"]:\n",
    "        w = (obj[\"xmax\"] - obj[\"xmin\"])/aw # make the width range between [0,GRID_W)\n",
    "        h = (obj[\"ymax\"] - obj[\"ymin\"])/ah # make the width range between [0,GRID_H)\n",
    "        temp = [w,h]\n",
    "        wh.append(temp)\n",
    "wh = np.array(wh)\n",
    "print(\"clustering feature data is ready. shape = (N object, width and height) =  {}\".format(wh.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the clustering data\n",
    "先来看看归一化后的anchor尺寸分布情况:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(wh[:,0],wh[:,1],alpha=0.3)\n",
    "plt.title(\"Clusters\",fontsize=20)\n",
    "plt.xlabel(\"normalized width\",fontsize=20)\n",
    "plt.ylabel(\"normalized height\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection over union\n",
    "\n",
    "在介绍使用K-means对先验边界框进行聚类时，非常有必要来讨论下iou的概念，因为后面我们会用它来衡量两个boundingbox之间的距离。iou是一种测量在特定数据集中检测相应物体准确度的一个标准。我们可以在很多物体检测挑战中，例如PASCAL VOC challenge中看多很多使用该标准的做法。我们计算两个bounding box的iou时，只需要使用它们的4个位置参数(xmin,ymin, width, height)，这里引用别人一张图:\n",
    "\n",
    "<img src=\"https://farm8.staticflickr.com/7813/46412972842_6d2af063e9_h.jpg\" width=\"300\" height=\"400\" alt=\"bbx\">\n",
    "\n",
    "iou的计算公式为: \n",
    "$$\\begin{array}{rl}\n",
    "IoU &= \\frac{\\textrm{intersection} }{\n",
    "\\textrm{union} - \\textrm{intersection}\n",
    "}\\\\\n",
    "\\textrm{intersection} &= Min(w_1,w_2)  Min(h_1,h_2)\\\\\n",
    "\\textrm{union} & = w_1 h_1 + w_2  h_2\n",
    "\\end{array}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def iou(box, clusters):\n",
    "    '''\n",
    "    :param box:      np.array of shape (2,) containing w and h\n",
    "    :param clusters: np.array of shape (N cluster, 2) \n",
    "    '''\n",
    "    x = np.minimum(clusters[:, 0], box[0]) \n",
    "    y = np.minimum(clusters[:, 1], box[1])\n",
    "\n",
    "    intersection = x * y\n",
    "    box_area = box[0] * box[1]\n",
    "    cluster_area = clusters[:, 0] * clusters[:, 1]\n",
    "\n",
    "    iou_ = intersection / (box_area + cluster_area - intersection)\n",
    "\n",
    "    return iou_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The k-means clustering\n",
    "\n",
    "K-means的聚类方法很简单，它主要包含两个步骤:\n",
    "\n",
    "\n",
    "首先初始化类别数量和聚类中心:\n",
    "\n",
    "- Step 1: 计算每个boundingbox与所有聚类中心的距离（1-iou)，选择最近的那个聚类中心作为它的类别\n",
    "- Step 2: 使用每个类别簇的均值来作为下次迭代计算的类别中心 <br>\n",
    "\n",
    "重复步骤1和2,直至每个类别的中心位置不再发生变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def kmeans(boxes, k, dist=np.median,seed=1):\n",
    "    \"\"\"\n",
    "    Calculates k-means clustering with the Intersection over Union (IoU) metric.\n",
    "    :param boxes: numpy array of shape (r, 2), where r is the number of rows\n",
    "    :param k: number of clusters\n",
    "    :param dist: distance function\n",
    "    :return: numpy array of shape (k, 2)\n",
    "    \"\"\"\n",
    "    rows = boxes.shape[0]\n",
    "\n",
    "    distances     = np.empty((rows, k)) ## N row x N cluster\n",
    "    last_clusters = np.zeros((rows,))\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # initialize the cluster centers to be k items\n",
    "    clusters = boxes[np.random.choice(rows, k, replace=False)]\n",
    "\n",
    "    while True:\n",
    "        # Step 1: allocate each item to the closest cluster centers\n",
    "        for icluster in range(k): # I made change to lars76's code here to make the code faster\n",
    "            distances[:,icluster] = 1 - iou(clusters[icluster], boxes)\n",
    "\n",
    "        nearest_clusters = np.argmin(distances, axis=1)\n",
    "\n",
    "        if (last_clusters == nearest_clusters).all():\n",
    "            break\n",
    "            \n",
    "        # Step 2: calculate the cluster centers as mean (or median) of all the cases in the clusters.\n",
    "        for cluster in range(k):\n",
    "            clusters[cluster] = dist(boxes[nearest_clusters == cluster], axis=0)\n",
    "\n",
    "        last_clusters = nearest_clusters\n",
    "\n",
    "    return clusters,nearest_clusters,distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of Clusters\n",
    "\n",
    "一般来说，anchor聚类的类别越多，那么yolo算法就越能在不同尺度下与真实框进行回归，但是这样也增加了很多计算量。(这对于一个号称 real-time 目标检测框架来说是极其尴尬的，因此作者也尽量减少boundingbox的数目)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "kmax = 10\n",
    "dist = np.mean\n",
    "results = {}\n",
    "\n",
    "for k in range(2,kmax):\n",
    "    clusters, nearest_clusters, distances = kmeans(wh,k,seed=2,dist=dist)\n",
    "    WithinClusterMeanDist = np.mean(distances[np.arange(distances.shape[0]),nearest_clusters])\n",
    "    result = {\"clusters\":             clusters,\n",
    "              \"nearest_clusters\":     nearest_clusters,\n",
    "              \"distances\":            distances,\n",
    "              \"WithinClusterMeanDist\": WithinClusterMeanDist}\n",
    "    print(\"{:2.0f} clusters: mean IoU = {:5.4f}\".format(k,1-result[\"WithinClusterMeanDist\"]))\n",
    "    results[k] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类别的数量越多，每个聚类簇的均值iou就越大，说明聚类簇里的boundingbox愈加紧贴在一起。有时候很难决定类别的数目，这也是k-means的一大痛点！在yolov2论文里设置了5个先验anchor，因此先来看看聚类数目从5到8的效果吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of k-means results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_cluster_result(plt,clusters,nearest_clusters,WithinClusterSumDist,wh,k):\n",
    "    for icluster in np.unique(nearest_clusters):\n",
    "        pick = nearest_clusters==icluster\n",
    "        c = current_palette[icluster]\n",
    "        plt.rc('font', size=8) \n",
    "        plt.plot(wh[pick,0],wh[pick,1],\"p\",\n",
    "                 color=c,\n",
    "                 alpha=0.5,label=\"cluster = {}, N = {:6.0f}\".format(icluster,np.sum(pick)))\n",
    "        plt.text(clusters[icluster,0],\n",
    "                 clusters[icluster,1],\n",
    "                 \"c{}\".format(icluster),\n",
    "                 fontsize=20,color=\"red\")\n",
    "        plt.title(\"Clusters=%d\" %k)\n",
    "        plt.xlabel(\"width\")\n",
    "        plt.ylabel(\"height\")\n",
    "    plt.legend(title=\"Mean IoU = {:5.4f}\".format(WithinClusterSumDist))  \n",
    "    \n",
    "import seaborn as sns\n",
    "current_palette = list(sns.xkcd_rgb.values())\n",
    "\n",
    "figsize = (15,35)\n",
    "count =1 \n",
    "fig = plt.figure(figsize=figsize)\n",
    "for k in range(5,9):\n",
    "    result               = results[k]\n",
    "    clusters             = result[\"clusters\"]\n",
    "    nearest_clusters     = result[\"nearest_clusters\"]\n",
    "    WithinClusterSumDist = result[\"WithinClusterMeanDist\"]\n",
    "    \n",
    "    ax = fig.add_subplot(kmax/2,2,count)\n",
    "    plot_cluster_result(plt,clusters,nearest_clusters,1 - WithinClusterSumDist,wh,k)\n",
    "    count += 1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}